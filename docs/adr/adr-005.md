# ADR-005: Retrieval Crítico - ColBERT para Dominios Sensibles

**Estado:** Propuesto  
**Fecha:** 2025-01-27  
**Contexto:** Pipeline RAG - Fase 3  
**Depende de:** ADR-002, ADR-003, ADR-004 (Infraestructura base evaluada)

## Decisión

Introducir RAGatouille/ColBERT como retriever secundario especializado para dominios críticos donde la precisión es intolerante al error (clínico, legal, financiero).

## Contexto

### Problema Actual
- Retrieval basado en embeddings densos tiene limitaciones en precisión
- Dominios críticos requieren precisión quirúrgica
- Falta de baseline medido para evaluar mejoras
- Coste computacional vs. beneficio no cuantificado

### Requerimientos
- Precisión superior en dominios críticos
- Evaluación comparativa con baseline existente
- Activación controlada por políticas de TaskDB
- Optimización de coste-beneficio

## Opciones Consideradas

### Opción A: Mantener retrieval actual
**Pros:**
- Sin cambios en infraestructura
- Coste computacional mínimo

**Contras:**
- Limitaciones de precisión en dominios críticos
- Riesgo de errores en casos sensibles

### Opción B: ColBERT (Elegida)
**Pros:**
- Precisión superior en retrieval
- Framework especializado (RAGatouille)
- Activación selectiva por dominio
- Evaluación comparativa posible

**Contras:**
- Mayor coste computacional
- Complejidad adicional en pipeline

### Opción C: Ensemble de retrievers
**Pros:**
- Combinación de fortalezas
- Flexibilidad en configuración

**Contras:**
- Complejidad extrema
- Coste computacional muy alto
- Dificultad de optimización

## Decisión

**Se adopta la Opción B: ColBERT para dominios críticos**

### Justificación
- Precisión quirúrgica en dominios donde el error no es tolerable
- Activación selectiva minimiza impacto en coste
- Baseline medido permite evaluación objetiva
- Framework maduro y validado (RAGatouille)

## Implementación

### Componentes
1. **ColBERT Adapter**: Integración con RAGatouille
2. **Domain Router**: Activación selectiva por políticas
3. **Comparative Evaluation**: Métricas vs. baseline
4. **Cost Control**: Monitoreo de recursos

### Dominios Críticos Identificados
- **Clínico**: Procedimientos médicos, diagnósticos
- **Legal**: Contratos, regulaciones, compliance
- **Financiero**: Políticas de riesgo, auditorías
- **Seguridad**: Procedimientos de emergencia

### Activación por Políticas
```yaml
# config/rag.yaml
retrieval:
  default: "dense_embedding"
  critical_domains:
    clinical:
      retriever: "colbert"
      threshold: 0.95
    legal:
      retriever: "colbert"
      threshold: 0.90
    financial:
      retriever: "colbert"
      threshold: 0.85
```

### Archivos Afectados
- `retrievers/colbert_adapter.ts` (adapter principal)
- `config/rag.yaml` (políticas de activación)
- `scripts/eval-retrieval-comparison.py` (evaluación comparativa)
- `monitoring/retrieval-costs.py` (monitoreo de costes)

### Métricas de Éxito
- Mejora en recall > 20% en dominios críticos
- Precisión > 95% en casos críticos
- Coste adicional < 30% del baseline
- Tiempo de respuesta < 2x del baseline

## Consecuencias

### Positivas
- ✅ Precisión quirúrgica en dominios críticos
- ✅ Reducción de errores en casos sensibles
- ✅ Activación selectiva minimiza coste
- ✅ Baseline medido para evaluación objetiva

### Negativas
- ⚠️ Mayor coste computacional
- ⚠️ Complejidad adicional en pipeline
- ⚠️ Dependencia externa (RAGatouille)

### Riesgos
- **Alto**: Degradación significativa de rendimiento
- **Medio**: Coste computacional no justificado
- **Bajo**: Incompatibilidad con casos específicos

## Estrategia de Evaluación

### Baseline Establishment
1. Medir métricas actuales en dominios críticos
2. Establecer umbrales de aceptación
3. Definir casos de prueba representativos

### Comparative Analysis
- **Recall@K**: Cobertura de información relevante
- **Precision@K**: Exactitud de resultados
- **MRR**: Mean Reciprocal Rank
- **Latency**: Tiempo de respuesta
- **Cost**: Recursos computacionales

### A/B Testing
- 10% tráfico a ColBERT en dominios críticos
- Monitoreo continuo de métricas
- Rollback automático en degradación

## Control de Costes

### Activación Inteligente
- Análisis de criticidad del query
- Activación solo en dominios predefinidos
- Fallback a retrieval estándar en caso de fallo

### Monitoreo
- Métricas de coste en tiempo real
- Alertas en umbrales predefinidos
- Dashboard de coste-beneficio

### Optimización
- Cache de resultados frecuentes
- Batch processing para queries similares
- Optimización de índices ColBERT

## Seguimiento

### Criterios de Éxito
- [ ] ColBERT integrado y funcionando
- [ ] Activación selectiva por políticas operativa
- [ ] Métricas comparativas disponibles
- [ ] Coste controlado dentro de umbrales

### Revisión
- **Fecha:** 60 días post-implementación
- **Responsable:** Equipo RAG + Product
- **Criterios:** Cumplimiento de métricas de éxito y justificación de coste-beneficio

## Rollback Plan

### Triggers de Rollback
- Degradación de rendimiento > 50%
- Coste computacional > 50% del baseline
- Errores críticos en dominios sensibles

### Procedimiento
1. Desactivación inmediata de ColBERT
2. Fallback a retrieval estándar
3. Análisis de causa raíz
4. Reevaluación de configuración

---

**Estado del Roadmap:** Completado - 4 ADRs secuenciales definidos
